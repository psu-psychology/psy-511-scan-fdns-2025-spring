<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-03-06">

<title>Perception – PSY 511.003</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-7931e10a13f2f51d5932bd5e1fda4e06.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../include/css/styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">PSY 511.003</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../schedule.html"> 
<span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../evaluation.html"> 
<span class="menu-text">Evaluation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../policies.html"> 
<span class="menu-text">Policies</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-exercises" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Exercises</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-exercises">    
        <li>
    <a class="dropdown-item" href="../exercises/ex01.html">
 <span class="dropdown-text">Exercise 01 • Levels/Terms</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex02.html">
 <span class="dropdown-text">Exercise 02 • Neuroanatomy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex03.html">
 <span class="dropdown-text">Exercise 03 • Neurophysiology I</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex04.html">
 <span class="dropdown-text">Exercise 04 • Neurophysiology II</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex05.html">
 <span class="dropdown-text">Exercise 05 • Neurochemistry</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex06.html">
 <span class="dropdown-text">Exercise 06 • Methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex07.html">
 <span class="dropdown-text">Exercise 07 • Evolution</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/ex08.html">
 <span class="dropdown-text">Exercise 08 • Development</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/final-project.html">
 <span class="dropdown-text">Final project</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="../resources/anatomy.html">
 <span class="dropdown-text">Neuroanatomy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../resources/cells.html">
 <span class="dropdown-text">Cellular neuroscience</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../resources/neurochemistry.html">
 <span class="dropdown-text">Neurochemistry</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../resources/methods.html">
 <span class="dropdown-text">Neuroscience methods</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../resources/evolution.html">
 <span class="dropdown-text">Evolution</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-supplemental" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Supplemental</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-supplemental">    
        <li>
    <a class="dropdown-item" href="../supplemental/ex01-themes.html">
 <span class="dropdown-text">Exercise 01 Themes</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link active" data-scroll-target="#the-big-picture">The big picture</a>
  <ul>
  <li><a href="#senses-as-perceptionaction-systems" id="toc-senses-as-perceptionaction-systems" class="nav-link" data-scroll-target="#senses-as-perceptionaction-systems">Senses as (perception/action) systems</a></li>
  <li><a href="#smartphone-as-metaphor" id="toc-smartphone-as-metaphor" class="nav-link" data-scroll-target="#smartphone-as-metaphor">Smartphone as metaphor</a></li>
  <li><a href="#perceptionaction-system-dimensions" id="toc-perceptionaction-system-dimensions" class="nav-link" data-scroll-target="#perceptionaction-system-dimensions">Perception/action system dimensions</a>
  <ul class="collapse">
  <li><a href="#questions-for-interoception" id="toc-questions-for-interoception" class="nav-link" data-scroll-target="#questions-for-interoception">Questions for interoception</a></li>
  <li><a href="#questions-for-exteroception" id="toc-questions-for-exteroception" class="nav-link" data-scroll-target="#questions-for-exteroception">Questions for exteroception</a></li>
  <li><a href="#questions-for-action" id="toc-questions-for-action" class="nav-link" data-scroll-target="#questions-for-action">Questions for action</a></li>
  </ul></li>
  <li><a href="#properties-of-the-world" id="toc-properties-of-the-world" class="nav-link" data-scroll-target="#properties-of-the-world">Properties of the world</a></li>
  </ul></li>
  <li><a href="#processing" id="toc-processing" class="nav-link" data-scroll-target="#processing">Processing</a>
  <ul>
  <li><a href="#physics-of-sensation" id="toc-physics-of-sensation" class="nav-link" data-scroll-target="#physics-of-sensation">Physics of sensation</a>
  <ul class="collapse">
  <li><a href="#psychophysics-from-physics-to-psychology" id="toc-psychophysics-from-physics-to-psychology" class="nav-link" data-scroll-target="#psychophysics-from-physics-to-psychology">Psychophysics (from physics to psychology)</a></li>
  <li><a href="#vision" id="toc-vision" class="nav-link" data-scroll-target="#vision">Vision</a></li>
  <li><a href="#audition" id="toc-audition" class="nav-link" data-scroll-target="#audition">Audition</a></li>
  <li><a href="#chemosensation" id="toc-chemosensation" class="nav-link" data-scroll-target="#chemosensation">Chemosensation</a></li>
  <li><a href="#somatosensation" id="toc-somatosensation" class="nav-link" data-scroll-target="#somatosensation">Somatosensation</a></li>
  <li><a href="#interoception" id="toc-interoception" class="nav-link" data-scroll-target="#interoception">Interoception</a></li>
  </ul></li>
  <li><a href="#features-of-sensory-signals" id="toc-features-of-sensory-signals" class="nav-link" data-scroll-target="#features-of-sensory-signals">Features of sensory signals</a>
  <ul class="collapse">
  <li><a href="#change-across-time" id="toc-change-across-time" class="nav-link" data-scroll-target="#change-across-time">Change across time</a></li>
  <li><a href="#consist-of-repeating-signals-e.g.-patterns" id="toc-consist-of-repeating-signals-e.g.-patterns" class="nav-link" data-scroll-target="#consist-of-repeating-signals-e.g.-patterns">Consist of repeating signals (e.g.&nbsp;patterns)</a></li>
  <li><a href="#compare-1-sensors-located-in-different-parts-of-the-body" id="toc-compare-1-sensors-located-in-different-parts-of-the-body" class="nav-link" data-scroll-target="#compare-1-sensors-located-in-different-parts-of-the-body">Compare (&gt;1) sensors located in different parts of the body</a></li>
  <li><a href="#receptive-fields" id="toc-receptive-fields" class="nav-link" data-scroll-target="#receptive-fields">“Receptive fields”</a></li>
  </ul></li>
  <li><a href="#topographic-maps" id="toc-topographic-maps" class="nav-link" data-scroll-target="#topographic-maps">Topographic maps</a>
  <ul class="collapse">
  <li><a href="#auditory-tonotopic-maps" id="toc-auditory-tonotopic-maps" class="nav-link" data-scroll-target="#auditory-tonotopic-maps">Auditory: Tonotopic maps</a></li>
  <li><a href="#visual-retinotopic-maps" id="toc-visual-retinotopic-maps" class="nav-link" data-scroll-target="#visual-retinotopic-maps">Visual: Retinotopic maps</a></li>
  <li><a href="#somatosensory-somatotopic-maps-in-s1-m1" id="toc-somatosensory-somatotopic-maps-in-s1-m1" class="nav-link" data-scroll-target="#somatosensory-somatotopic-maps-in-s1-m1">Somatosensory: Somatotopic maps in S1 &amp; M1</a></li>
  </ul></li>
  <li><a href="#sensivity-non-uniform" id="toc-sensivity-non-uniform" class="nav-link" data-scroll-target="#sensivity-non-uniform">Sensivity non-uniform</a>
  <ul class="collapse">
  <li><a href="#two-point-touch-thresholds" id="toc-two-point-touch-thresholds" class="nav-link" data-scroll-target="#two-point-touch-thresholds">Two-point touch thresholds</a></li>
  <li><a href="#somatosensory-homunculus" id="toc-somatosensory-homunculus" class="nav-link" data-scroll-target="#somatosensory-homunculus">Somatosensory homunculus</a></li>
  <li><a href="#visual-acuity-non-uniform" id="toc-visual-acuity-non-uniform" class="nav-link" data-scroll-target="#visual-acuity-non-uniform">Visual acuity non-uniform</a></li>
  <li><a href="#hearing-thresholds-non-uniform" id="toc-hearing-thresholds-non-uniform" class="nav-link" data-scroll-target="#hearing-thresholds-non-uniform">Hearing thresholds non-uniform</a></li>
  </ul></li>
  <li><a href="#hierarchicalsequential-and-parallel" id="toc-hierarchicalsequential-and-parallel" class="nav-link" data-scroll-target="#hierarchicalsequential-and-parallel">Hierarchical/sequential AND parallel</a></li>
  <li><a href="#feedforward-and-feedback" id="toc-feedforward-and-feedback" class="nav-link" data-scroll-target="#feedforward-and-feedback">Feedforward and feedback</a></li>
  </ul></li>
  <li><a href="#case-study-vision" id="toc-case-study-vision" class="nav-link" data-scroll-target="#case-study-vision">Case study: Vision</a>
  <ul>
  <li><a href="#animals-respond-to-visual-illusions-too" id="toc-animals-respond-to-visual-illusions-too" class="nav-link" data-scroll-target="#animals-respond-to-visual-illusions-too">Animals respond to visual illusions, too</a></li>
  <li><a href="#properties-of-electromagnetic-em-radiation" id="toc-properties-of-electromagnetic-em-radiation" class="nav-link" data-scroll-target="#properties-of-electromagnetic-em-radiation">Properties of Electromagnetic (EM) radiation</a>
  <ul class="collapse">
  <li><a href="#reflectance-spectra-differ-by-surface" id="toc-reflectance-spectra-differ-by-surface" class="nav-link" data-scroll-target="#reflectance-spectra-differ-by-surface">Reflectance spectra differ by surface</a></li>
  <li><a href="#optic-array-specifies-geometry-of-environment" id="toc-optic-array-specifies-geometry-of-environment" class="nav-link" data-scroll-target="#optic-array-specifies-geometry-of-environment">Optic array specifies geometry of environment</a></li>
  <li><a href="#categories-of-wavelength-specify-perception-of-color" id="toc-categories-of-wavelength-specify-perception-of-color" class="nav-link" data-scroll-target="#categories-of-wavelength-specify-perception-of-color">Categories of wavelength specify perception of color</a></li>
  </ul></li>
  <li><a href="#the-biological-camera" id="toc-the-biological-camera" class="nav-link" data-scroll-target="#the-biological-camera">The biological camera</a>
  <ul class="collapse">
  <li><a href="#part-of-a-self-stabilizing-system" id="toc-part-of-a-self-stabilizing-system" class="nav-link" data-scroll-target="#part-of-a-self-stabilizing-system">part of a self-stabilizing system…</a></li>
  <li><a href="#parts-of-the-eye" id="toc-parts-of-the-eye" class="nav-link" data-scroll-target="#parts-of-the-eye">Parts of the eye</a></li>
  <li><a href="#geometry-of-retinal-image" id="toc-geometry-of-retinal-image" class="nav-link" data-scroll-target="#geometry-of-retinal-image">Geometry of retinal image</a></li>
  <li><a href="#the-fovea" id="toc-the-fovea" class="nav-link" data-scroll-target="#the-fovea">The <em>fovea</em></a></li>
  <li><a href="#photoreceptors-in-retina-detect-light" id="toc-photoreceptors-in-retina-detect-light" class="nav-link" data-scroll-target="#photoreceptors-in-retina-detect-light"><em>Photoreceptors</em> in retina detect light</a></li>
  <li><a href="#photoreceptor-physiology" id="toc-photoreceptor-physiology" class="nav-link" data-scroll-target="#photoreceptor-physiology">Photoreceptor physiology</a></li>
  </ul></li>
  <li><a href="#retina" id="toc-retina" class="nav-link" data-scroll-target="#retina">Retina</a>
  <ul class="collapse">
  <li><a href="#center-surround-receptive-fields" id="toc-center-surround-receptive-fields" class="nav-link" data-scroll-target="#center-surround-receptive-fields">Center-surround receptive fields</a></li>
  <li><a href="#opponent-processing" id="toc-opponent-processing" class="nav-link" data-scroll-target="#opponent-processing">Opponent processing</a></li>
  </ul></li>
  <li><a href="#from-eye-to-brain" id="toc-from-eye-to-brain" class="nav-link" data-scroll-target="#from-eye-to-brain">From eye to brain</a>
  <ul class="collapse">
  <li><a href="#lgn" id="toc-lgn" class="nav-link" data-scroll-target="#lgn">LGN</a></li>
  <li><a href="#from-lgn-to-v1" id="toc-from-lgn-to-v1" class="nav-link" data-scroll-target="#from-lgn-to-v1">From LGN to V1</a></li>
  <li><a href="#human-v1" id="toc-human-v1" class="nav-link" data-scroll-target="#human-v1">Human V1</a></li>
  <li><a href="#laminar-columnar-organization" id="toc-laminar-columnar-organization" class="nav-link" data-scroll-target="#laminar-columnar-organization">Laminar, columnar organization</a></li>
  <li><a href="#from-center-surround-receptive-fields-to-line-detection" id="toc-from-center-surround-receptive-fields-to-line-detection" class="nav-link" data-scroll-target="#from-center-surround-receptive-fields-to-line-detection">From center-surround receptive fields to line detection</a></li>
  <li><a href="#ocular-dominance-columns" id="toc-ocular-dominance-columns" class="nav-link" data-scroll-target="#ocular-dominance-columns">Ocular dominance columns</a></li>
  </ul></li>
  <li><a href="#beyond-v1" id="toc-beyond-v1" class="nav-link" data-scroll-target="#beyond-v1">Beyond V1</a></li>
  <li><a href="#what-is-vision-for" id="toc-what-is-vision-for" class="nav-link" data-scroll-target="#what-is-vision-for">What is vision for?</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/psu-psychology/psy-511-scan-fdns-2025-spring/edit/main/src/resources/perception.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/psu-psychology/psy-511-scan-fdns-2025-spring/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Perception</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 6, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">March 14, 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="the-big-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-big-picture">The big picture</h2>
<section id="senses-as-perceptionaction-systems" class="level3">
<h3 class="anchored" data-anchor-id="senses-as-perceptionaction-systems">Senses as (perception/action) systems</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="perception_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://images-na.ssl-images-amazon.com/images/I/31fzXc46omL._SX312_BO1,204,203,200_.jpg" class="img-fluid figure-img"></p>
<figcaption>Gibson 1966</figcaption>
</figure>
</div>
<p><img src="../include/img/perception-action-cycle.jpg" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/swanson-book-fig-10.12.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="swanson2012brain">(Figure 10.2 from <a href="#ref-swanson2012brain" role="doc-biblioref">Swanson, 2012</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/swanson-2005-fig-1.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="swanson2005anatomy">(Figure 1 from <a href="#ref-swanson2005anatomy" role="doc-biblioref">Swanson, 2005</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="smartphone-as-metaphor" class="level3">
<h3 class="anchored" data-anchor-id="smartphone-as-metaphor">Smartphone as metaphor</h3>
<ul>
<li>Accelerometer</li>
<li>Gyroscope</li>
<li>Magnetometer</li>
<li>Proximity sensor</li>
<li>Ambient light sensor</li>
<li>Barometer</li>
<li>Thermometer</li>
<li>Mic</li>
<li>Camera</li>
<li>Radios (Bluetooth, wifi, cellular, GPS)</li>
</ul>
<p><a href="http://www.phonearena.com/news/Did-you-know-how-many-different-kinds-of-sensors-go-inside-a-smartphone_id57885" class="uri">http://www.phonearena.com/news/Did-you-know-how-many-different-kinds-of-sensors-go-inside-a-smartphone_id57885</a></p>
</section>
<section id="perceptionaction-system-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="perceptionaction-system-dimensions">Perception/action system dimensions</h3>
<ul>
<li>Interoceptive
<ul>
<li>Body position, movement, posture</li>
<li>Internal status: hunger, thirst, arousal, discomfort/pain, etc.</li>
</ul></li>
<li>Exteroceptive
<ul>
<li>Layout of environment, contents</li>
</ul></li>
</ul>
<section id="questions-for-interoception" class="level4">
<h4 class="anchored" data-anchor-id="questions-for-interoception">Questions for interoception</h4>
<ul>
<li>Tired or rested?</li>
<li>Well or ill?</li>
<li>Hungry or thirsty or sated?</li>
<li>Stressed vs.&nbsp;coping?</li>
<li>Emotional state?</li>
</ul>
</section>
<section id="questions-for-exteroception" class="level4">
<h4 class="anchored" data-anchor-id="questions-for-exteroception">Questions for exteroception</h4>
<ul>
<li>Who/What is out there?</li>
<li>Animate/inanimate?
<ul>
<li>Conspecific (same species)/non?</li>
<li>Threat/non?</li>
<li>Familiar/un?</li>
<li>Mate/non? or Friend/not?</li>
<li>Food source/non</li>
</ul></li>
<li>Where is it?
<ul>
<li>Distance
<ul>
<li>Proximal</li>
<li>Distal</li>
</ul></li>
<li>Elevation, azimuth</li>
<li>Coordinate frames
<ul>
<li>Self/ego (left of me)</li>
<li>Object (top of object)</li>
<li>Allo/world (North of College)</li>
</ul></li>
</ul></li>
<li>Where moving?</li>
</ul>
</section>
<section id="questions-for-action" class="level4">
<h4 class="anchored" data-anchor-id="questions-for-action">Questions for action</h4>
<ul>
<li>What kind of response?
<ul>
<li>External
<ul>
<li>Move body
<ul>
<li>Approach/avoid/freeze</li>
<li>Signal/remain silent</li>
<li>Manipulate</li>
</ul></li>
</ul></li>
<li>Internal
<ul>
<li>Change physiological state</li>
</ul></li>
</ul></li>
<li>Speed, quality, direction of response</li>
</ul>
<!-- ## From world to brain -->
<!-- ```{r} -->
<!-- knitr::include_graphics("../include/img/nested-causality.jpeg") -->
<!-- ``` -->
<!-- | Realm               | Domain               | -->
<!-- |---------------------|----------------------| -->
<!-- | $W$                 | The world            | -->
<!-- | $B$                 | The body             | -->
<!-- | $N$                 | The nervous system   | -->
<!-- | $M$                 | The mind             | -->
</section>
</section>
<section id="properties-of-the-world" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-the-world">Properties of the world</h3>
<ul>
<li>Behaviorally relevant conditions, events, and entities…</li>
<li>Generate patterns…
<ul>
<li>Chemical</li>
<li>Photic/electromagnetic</li>
<li>Mechanical/acoustic</li>
</ul></li>
<li>That specialized sensors detect, and</li>
<li>Neural circuitry responds to</li>
<li>That yield internal states (short- and long-term)</li>
<li>That cause actions</li>
</ul>
</section>
</section>
<section id="processing" class="level2">
<h2 class="anchored" data-anchor-id="processing">Processing</h2>
<section id="physics-of-sensation" class="level3">
<h3 class="anchored" data-anchor-id="physics-of-sensation">Physics of sensation</h3>
<p>Sorry, Mrs.&nbsp;Potraz, there are more than five senses!</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Informal name</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Vision</td>
<td>Electromagnetic radiation</td>
</tr>
<tr class="even">
<td>Audition</td>
<td>Mechanical vibration in air/water</td>
</tr>
<tr class="odd">
<td>Touch</td>
<td>Mechanical vibration of skin on surface</td>
</tr>
<tr class="even">
<td>Vestibular</td>
<td>Rotation &amp; linear acceleration of head</td>
</tr>
<tr class="odd">
<td>Olfaction</td>
<td>Chemical patterns in air/water</td>
</tr>
<tr class="even">
<td>Gustation</td>
<td>Chemical patterns in mouth</td>
</tr>
<tr class="odd">
<td>Electroception</td>
<td>Electromagnetic radiation</td>
</tr>
<tr class="even">
<td>Magnetoreception</td>
<td>Electromagnetic radiation patterns</td>
</tr>
<tr class="odd">
<td>Kinesthesia</td>
<td>Position, velocity, acceleration of limbs, body</td>
</tr>
</tbody>
</table>
<section id="psychophysics-from-physics-to-psychology" class="level4">
<h4 class="anchored" data-anchor-id="psychophysics-from-physics-to-psychology">Psychophysics (from physics to psychology)</h4>
<ul>
<li>What is the energy/chemical channel?</li>
<li>Channels carry different types of information about
<ul>
<li><em>What</em> is out there?</li>
<li><em>Where</em> is it located or moving?</li>
</ul></li>
<li>Convey information at different rates, with varied precision</li>
<li>Information often signaled by multiple sources</li>
</ul>
</section>
<section id="vision" class="level4">
<h4 class="anchored" data-anchor-id="vision">Vision</h4>
<ul>
<li>Source: Electromagnetic radiation
<ul>
<li>Reflected from surfaces</li>
</ul></li>
<li>What is it?
<ul>
<li>Shape, size, surface properties (color, texture, reflectance, etc.)</li>
<li>Wavelength/frequency, intensity</li>
</ul></li>
<li>Where is it?
<ul>
<li>Position: Left/right; up/down on retina</li>
<li>Near/far: retinal disparity, interposition, height above horizon…</li>
<li>Orientation, motion</li>
</ul></li>
</ul>
</section>
<section id="audition" class="level4">
<h4 class="anchored" data-anchor-id="audition">Audition</h4>
<ul>
<li>Source: Mechanical vibrations in air or water</li>
<li>What is it?
<ul>
<li>Pattern of frequencies, amplitudes, durations</li>
</ul></li>
<li>Where is it?
<ul>
<li>Left/right or up/down: Interaural time/phase, intensity differences, pinnae filtering</li>
<li>Motion: Frequency shifts via Doppler effect</li>
</ul></li>
</ul>
</section>
<section id="chemosensation" class="level4">
<h4 class="anchored" data-anchor-id="chemosensation">Chemosensation</h4>
<ul>
<li>Source: Chemicals in mouth, nasal cavity</li>
<li>What is it?
<ul>
<li>Mixtures of chemicals</li>
</ul></li>
<li>Where is it?
<ul>
<li>Left/right; up/down; near/far via intensity gradients</li>
</ul></li>
</ul>
</section>
<section id="somatosensation" class="level4">
<h4 class="anchored" data-anchor-id="somatosensation">Somatosensation</h4>
<ul>
<li>Source: Thermal or mechanical stimulation (vibration/pressure) of skin</li>
<li>What is it?
<ul>
<li>Shape, size, smoothness, mass, temperature, deformability: Pattern of stimulation</li>
</ul></li>
<li>Where it it?
<ul>
<li>Pattern of cutaneous receptors on skin</li>
</ul></li>
</ul>
</section>
<section id="interoception" class="level4">
<h4 class="anchored" data-anchor-id="interoception">Interoception</h4>
<ul>
<li>Hunger/thirst
<ul>
<li>Receptors for nutrient, fluid levels</li>
</ul></li>
<li>Energy levels
<ul>
<li>Receptors for hormones, NTs</li>
<li>ANS responses</li>
</ul></li>
<li>Temperature
<ul>
<li>Receptors in skin, viscera</li>
</ul></li>
<li>Mating interest
<ul>
<li>Receptors for hormones, NTs</li>
<li>ANS responses</li>
</ul></li>
<li>Body position &amp; movement (proprioception)
<ul>
<li>Receptors in muscles, joints, skin</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0166223617300176-gr2.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Namkung2017-gc">(Figure 2 from <a href="#ref-Namkung2017-gc" role="doc-biblioref">Namkung, Kim, &amp; Sawa, 2017</a>)</span>. Figure 2. Interoceptive Information and Its Integration with Emotional, Cognitive, and Motivational Signals from an Array of Cortical and Subcortical Regions. Interoceptive information of constantly changing body states arrives in the posterior insula by ascending sensory inputs from dedicated spinal and brainstem pathways via specific thalamic relays. This information is projected rostrally onto the anterior insula, where it is integrated with emotional, cognitive, and motivational signals from an array of cortical and subcortical regions. As a result, the anterior insula supports unique subjective feeling states. The anterior insula regulates the introduction of subjective feelings into cognitive and motivational processes by virtue of its cortical location at the cross-roads of numerous pathways involved in higher cognition and motivation. Abbreviations: AI, anterior insula; AMG, amygdala; dACC, dorsal anterior cingulate cortex; DLPFC, dorsolateral prefrontal cortex; PI, posterior insula; THAL, thalamus; VMPFC, ventromedial prefrontal cortex; VS, ventral striatum.</figcaption>
</figure>
</div>
</section>
</section>
<section id="features-of-sensory-signals" class="level3">
<h3 class="anchored" data-anchor-id="features-of-sensory-signals">Features of sensory signals</h3>
<section id="change-across-time" class="level4">
<h4 class="anchored" data-anchor-id="change-across-time">Change across time</h4>
<ul>
<li>Tonic (sustained) vs.&nbsp;phasic (transient) responses</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.researchgate.net/publication/51231510/figure/fig1/AS:202984857313285@1425406769897/Two-types-of-receptions-differing-by-the-rate-of-adaptation-to-the-dynamical-stimulus-A.png" class="img-fluid figure-img"></p>
<figcaption>https://www.researchgate.net/figure/Two-types-of-receptions-differing-by-the-rate-of-adaptation-to-the-dynamical-stimulus-A_fig1_51231510</figcaption>
</figure>
</div>
<ul>
<li>Adaptation
<ul>
<li>Decline in sensitivity with sustained stimulation</li>
<li>Most sensory systems attuned to change</li>
</ul></li>
<li>Just noticeable difference (JND): How much of a change is noticeable?
<ul>
<li>Most psychophysical functions are non-linear</li>
<li>JND a function of absolute intensity!</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.psywww.com/intropsych/ch04-senses/04stevenscurves.jpg" class="img-fluid figure-img"></p>
<figcaption>Psychophysical functions</figcaption>
</figure>
</div>
<ul>
<li>Information propagates in CNS at different speeds
<ul>
<li>Bigger diameter: Faster</li>
<li>Denser myelin: Faster</li>
</ul></li>
</ul>
<iframe width="800px" height="800px" src="https://en.wikipedia.org/wiki/Nerve_conduction_velocity">
</iframe>
</section>
<section id="consist-of-repeating-signals-e.g.-patterns" class="level4">
<h4 class="anchored" data-anchor-id="consist-of-repeating-signals-e.g.-patterns">Consist of repeating signals (e.g.&nbsp;patterns)</h4>
<ul>
<li>In space (textures)</li>
<li>In time</li>
</ul>
<section id="vision-spatial-frequencycontrast-sensitivity" class="level5">
<h5 class="anchored" data-anchor-id="vision-spatial-frequencycontrast-sensitivity">Vision: Spatial frequency/contrast sensitivity</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://onlinelibrary.wiley.com/cms/asset/b8b78ab1-4a85-4add-86cb-d389fb0988b1/mnfr3528-fig-0001-m.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Roark2019-fx">(<a href="#ref-Roark2019-fx" role="doc-biblioref">Roark &amp; Stringham, 2019</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="audition-frequencies-in-sound" class="level5">
<h5 class="anchored" data-anchor-id="audition-frequencies-in-sound">Audition: Frequencies in sound</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.mwmresearchgroup.org/uploads/3/0/8/6/30861243/image-2-ft_orig.png" class="img-fluid figure-img"></p>
<figcaption>https://www.mwmresearchgroup.org/blog/key-concepts-fourier-transforms-and-signal-processing</figcaption>
</figure>
</div>
</section>
<section id="somatosensation-textures" class="level5">
<h5 class="anchored" data-anchor-id="somatosensation-textures">Somatosensation: Textures</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.frontiersin.org/files/Articles/862344/fnhum-16-862344-HTML/image_m/fnhum-16-862344-g001.jpg" class="img-fluid figure-img"></p>
<figcaption>Figure 1 from https://www.frontiersin.org/articles/10.3389/fnhum.2022.862344/full</figcaption>
</figure>
</div>
</section>
</section>
<section id="compare-1-sensors-located-in-different-parts-of-the-body" class="level4">
<h4 class="anchored" data-anchor-id="compare-1-sensors-located-in-different-parts-of-the-body">Compare (&gt;1) sensors located in different parts of the body</h4>
<ul>
<li>Eyes</li>
<li>Ears</li>
<li>Skin surface</li>
<li>Nostrils</li>
<li>Tongue</li>
</ul>
<p><img src="https://images.unsplash.com/photo-1519699486208-1293e479cb98?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;w=1000&amp;q=80" class="img-fluid"></p>
</section>
<section id="receptive-fields" class="level4">
<h4 class="anchored" data-anchor-id="receptive-fields"><a href="https://en.wikipedia.org/wiki/Receptive_field">“Receptive fields”</a></h4>
<ul>
<li>Area on sensory surface (e.g., retina, skin) that when stimulated changes neuron’s firing</li>
</ul>
<section id="tactile" class="level5">
<h5 class="anchored" data-anchor-id="tactile">Tactile</h5>
<p><img src="https://i.stack.imgur.com/br9Zo.jpg" class="img-fluid" alt="https://www.nursinghero.com/study-guides/austincc-ap1/pain"> ##### Visual</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://openbooks.lib.msu.edu/app/uploads/sites/6/2021/03/RetinalReceptiveField.png" class="img-fluid figure-img"></p>
<figcaption>https://openbooks.lib.msu.edu/neuroscience/chapter/vision-the-retina/</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://foundationsofvision.stanford.edu/wp-content/uploads/2012/02/orientedRF-1024x602.png" class="img-fluid figure-img"></p>
<figcaption>https://foundationsofvision.stanford.edu/chapter-6-the-cortical-representation/</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="topographic-maps" class="level3">
<h3 class="anchored" data-anchor-id="topographic-maps">Topographic maps</h3>
<section id="auditory-tonotopic-maps" class="level4">
<h4 class="anchored" data-anchor-id="auditory-tonotopic-maps">Auditory: Tonotopic maps</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2830355/bin/nihms172043f3.jpg" class="img-fluid figure-img"></p>
<figcaption>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2830355/</figcaption>
</figure>
</div>
</section>
<section id="visual-retinotopic-maps" class="level4">
<h4 class="anchored" data-anchor-id="visual-retinotopic-maps">Visual: Retinotopic maps</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arvo.silverchair-cdn.com/arvo/content_public/journal/jov/933499/m_jov-3-10-1-fig001.jpeg?Expires=1712666457&amp;Signature=XlOZhjDHS06YKBtQLQWg5mlbK9qEaZNgrqDF2UhAJCnpfm8O5LlSnNbBmjTJ1Sd9Ky8q6MfrknY7gbQgFtyK-BmAkRNb0WaAylDNNiZUbkAYjYQuKlkvXkZQX1sPByx5TyRdQfNmu4XCiMfFTeltgAztX5VE7IIFQIWojSJpSD475nwDflQIn7Td69K5UoYe5IqHWDM510pVwEuJibdqd6tXxbum6etzqbhZh7SJ1qJfMo8vjzRRNd56uRHMoSk~bVHNvQNain~hOde-XSI094TuQlVDeYl8GUyNnU8MWNxf50ZyPtgwuo-bo8PksqCH9ez3fz2ORrPHLSbntp8-7g__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="dougherty_visual_2003">(<a href="#ref-dougherty_visual_2003" role="doc-biblioref">Dougherty et al., 2003</a>)</span></figcaption>
</figure>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/f2JMbo4BZqY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rsykP-9-moA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="somatosensory-somatotopic-maps-in-s1-m1" class="level4">
<h4 class="anchored" data-anchor-id="somatosensory-somatotopic-maps-in-s1-m1">Somatosensory: Somatotopic maps in S1 &amp; M1</h4>
<p><img src="http://bio1152.nicerweb.com/Locked/media/ch49/49_16-MotorSensoryCorts-L.jpg" class="img-fluid"></p>
</section>
</section>
<section id="sensivity-non-uniform" class="level3">
<h3 class="anchored" data-anchor-id="sensivity-non-uniform">Sensivity non-uniform</h3>
<section id="two-point-touch-thresholds" class="level4">
<h4 class="anchored" data-anchor-id="two-point-touch-thresholds">Two-point touch thresholds</h4>
<p><img src="../include/img/two-point-thresholds.jpg" class="img-fluid"></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/t97QiEiKjD8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="somatosensory-homunculus" class="level4">
<h4 class="anchored" data-anchor-id="somatosensory-homunculus">Somatosensory homunculus</h4>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/5/51/Front_of_Sensory_Homunculus.gif" class="img-fluid"></p>
</section>
<section id="visual-acuity-non-uniform" class="level4">
<h4 class="anchored" data-anchor-id="visual-acuity-non-uniform">Visual acuity non-uniform</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/AcuityHumanEye.svg/270px-AcuityHumanEye.svg.png" class="img-fluid figure-img"></p>
<figcaption>Wikipedia</figcaption>
</figure>
</div>
</section>
<section id="hearing-thresholds-non-uniform" class="level4">
<h4 class="anchored" data-anchor-id="hearing-thresholds-non-uniform">Hearing thresholds non-uniform</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="http://auditoryneuroscience.com/sites/default/files/inline-images/HLdata_0.png" class="img-fluid figure-img"></p>
<figcaption>http://auditoryneuroscience.com/</figcaption>
</figure>
</div>
</section>
</section>
<section id="hierarchicalsequential-and-parallel" class="level3">
<h3 class="anchored" data-anchor-id="hierarchicalsequential-and-parallel">Hierarchical/sequential AND parallel</h3>
<p><img src="../include/img/swanson-11.4.jpg" class="img-fluid"></p>
<p><img src="../include/img/biopsych-fig-5.5.jpg" class="img-fluid"></p>
<p><img src="../include/img/biospsych-labeled-lines.jpg" class="img-fluid"></p>
</section>
<section id="feedforward-and-feedback" class="level3">
<h3 class="anchored" data-anchor-id="feedforward-and-feedback">Feedforward and feedback</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="perception_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="case-study-vision" class="level2">
<h2 class="anchored" data-anchor-id="case-study-vision">Case study: Vision</h2>
<section id="animals-respond-to-visual-illusions-too" class="level3">
<h3 class="anchored" data-anchor-id="animals-respond-to-visual-illusions-too">Animals respond to visual illusions, too</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.illusionsindex.org/images/illusions/Rotating-Snakes/42_rotsnakes_main.jpg" class="img-fluid figure-img"></p>
<figcaption>https://www.illusionsindex.org/i/rotating-snakes</figcaption>
</figure>
</div>
<p><strong>A cat responds…</strong></p>
<p><a href="https://www.reddit.com/r/youseeingthisshit/comments/p9y7v1/the_reaction_of_the_cat_on_the_optical_illusion/?ref=share&amp;ref_source=embed&amp;utm_content=title&amp;utm_medium=post_embed&amp;utm_name=85f1a01593f447e092c5b300e5561d6e&amp;utm_source=embedly&amp;utm_term=p9y7v1" class="uri">https://www.reddit.com/r/youseeingthisshit/comments/p9y7v1/the_reaction_of_the_cat_on_the_optical_illusion/?ref=share&amp;ref_source=embed&amp;utm_content=title&amp;utm_medium=post_embed&amp;utm_name=85f1a01593f447e092c5b300e5561d6e&amp;utm_source=embedly&amp;utm_term=p9y7v1</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0168159121001258-gr4.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Smith2021-ho">(<a href="#ref-Smith2021-ho" role="doc-biblioref">Smith, Chouinard, &amp; Byosiere, 2021</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0168159121001258-gr5_lrg.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Smith2021-ho">(<a href="#ref-Smith2021-ho" role="doc-biblioref">Smith et al., 2021</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="properties-of-electromagnetic-em-radiation" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-electromagnetic-em-radiation">Properties of Electromagnetic (EM) radiation</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/em-spectrum.jpg" class="img-fluid figure-img"></p>
<figcaption>http://en.wikipedia.org/wiki/File:EM_Spectrum_Properties_edit.svg</figcaption>
</figure>
</div>
<ul>
<li>Wavelength/frequency</li>
<li>Intensity</li>
<li>Location/position of source</li>
<li>Reflects off some materials</li>
<li>Refracted (bent) moving through other materials</li>
<li>Information across space (and time)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/hud2014_1000c.jpg" class="img-fluid figure-img"></p>
<figcaption>http://apod.nasa.gov/apod/ap140605.html</figcaption>
</figure>
</div>
<ul>
<li>Light provides fast (2.99 million m/s; 186 million mi/hr) information about surfaces at a distance</li>
<li>vs.&nbsp;sound (340 m/s; 767 mi/hr)</li>
<li>vs.&nbsp;chemical signals (min/mi)</li>
</ul>
<section id="reflectance-spectra-differ-by-surface" class="level4">
<h4 class="anchored" data-anchor-id="reflectance-spectra-differ-by-surface">Reflectance spectra differ by surface</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.researchgate.net/profile/Lise-Lyngsnes-Randeberg/publication/265397843/figure/fig8/AS:667691706773516@1536201516532/Reflectance-spectra-from-different-skin-types-measured-using-the-Ocean-Optics-SD-2000.png" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="Randeberg2005-xn">Randeberg (<a href="#ref-Randeberg2005-xn" role="doc-biblioref">2005</a>)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/reflectance-spectrum.gif" class="img-fluid figure-img"></p>
<figcaption>http://http://www.vgt.vito.be/userguide/book_1/4/42/ie42bd.gif</figcaption>
</figure>
</div>
</section>
<section id="optic-array-specifies-geometry-of-environment" class="level4">
<h4 class="anchored" data-anchor-id="optic-array-specifies-geometry-of-environment"><a href="https://en.wikipedia.org/wiki/Ambient_optic_array">Optic array</a> specifies geometry of environment</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/OpticArray.jpg" class="img-fluid figure-img"></p>
<figcaption>Gibson</figcaption>
</figure>
</div>
</section>
<section id="categories-of-wavelength-specify-perception-of-color" class="level4">
<h4 class="anchored" data-anchor-id="categories-of-wavelength-specify-perception-of-color">Categories of wavelength specify perception of color</h4>
<ul>
<li>Eyes categorize wavelength into relative intensities within wavelength bands</li>
<li>RGB ~ <span class="red"><strong>R</strong>ed</span>, <span class="green"><strong>G</strong>reen</span>, <span class="blue"><strong>B</strong>lue</span>
<ul>
<li>Long, medium, short wavelengths</li>
</ul></li>
<li><em>Color is a neural/psychological construct</em></li>
</ul>
<p><img src="../include/img/rgb-monitor.jpg" class="img-fluid"></p>
</section>
</section>
<section id="the-biological-camera" class="level3">
<h3 class="anchored" data-anchor-id="the-biological-camera">The biological camera</h3>
<p><img src="../include/img/how-camera-works.jpg" class="img-fluid"></p>
<p><img src="../include/img/the-eye-ksj.jpg" class="img-fluid"></p>
<p><img src="../include/img/the-eye.jpg" class="img-fluid"></p>
<section id="part-of-a-self-stabilizing-system" class="level4">
<h4 class="anchored" data-anchor-id="part-of-a-self-stabilizing-system">part of a self-stabilizing system…</h4>
<!-- Kestrel showing image stabilization -->
<iframe width="560" height="315" src="https://www.youtube.com/embed/JGArTWOJtXs?start=7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p><a href="https://www.youtube.com/embed/JGArTWOJtXs" class="uri">https://www.youtube.com/embed/JGArTWOJtXs</a></p>
</section>
<section id="parts-of-the-eye" class="level4">
<h4 class="anchored" data-anchor-id="parts-of-the-eye">Parts of the eye</h4>
<ul>
<li><em>Cornea</em> - refraction (2/3 of total)</li>
<li><em>Pupil</em> - light intensity; diameter regulated by Iris.</li>
<li><em>Lens</em> - refraction (remaining 1/3; focus)</li>
<li><em>Retina</em> - light detection
<ul>
<li>~ skin or organ of Corti in inner ear</li>
</ul></li>
<li><em>Pigment epithelium</em> - regenerate photopigment</li>
<li><em>Muscles</em> - move eye, reshape lens, change pupil diameter</li>
</ul>
</section>
<section id="geometry-of-retinal-image" class="level4">
<h4 class="anchored" data-anchor-id="geometry-of-retinal-image">Geometry of retinal image</h4>
<ul>
<li>Image inverted (up/down)</li>
<li>Image reversed (left/right)</li>
<li>Point-to-point map (<em>retinotopic</em>)</li>
<li>Binocular and monocular zones</li>
</ul>
<p><img src="../include/img/retinal-image.jpg" class="img-fluid"></p>
<p><img src="../include/img/visual-fields.jpg" class="img-fluid"></p>
</section>
<section id="the-fovea" class="level4">
<h4 class="anchored" data-anchor-id="the-fovea">The <em>fovea</em></h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/fovea.jpg" class="img-fluid figure-img"></p>
<figcaption>http://www.brainhq.com/sites/default/files/fovea.jpg</figcaption>
</figure>
</div>
<ul>
<li>Central 1-2 deg of visual field</li>
<li>Aligned with visual axis</li>
<li><em>Retinal ganglion cells</em> pushed aside</li>
<li>Highest <em>acuity</em> vision == best for details</li>
<li>Acuity varies from center to periphery</li>
</ul>
<p><img src="../include/img/acuity-across-visual-field.jpg" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/acuity-across-visual-field-graph.jpg" class="img-fluid figure-img"></p>
<figcaption>http://michaeldmann.net/pix_7/blndspot.gif</figcaption>
</figure>
</div>
<section id="what-part-of-the-skin-is-like-the-fovea" class="level5">
<h5 class="anchored" data-anchor-id="what-part-of-the-skin-is-like-the-fovea">What part of the skin is like the fovea?</h5>
<p><img src="../include/img/two-point-thresholds.jpg" class="img-fluid"></p>
</section>
</section>
<section id="photoreceptors-in-retina-detect-light" class="level4">
<h4 class="anchored" data-anchor-id="photoreceptors-in-retina-detect-light"><em>Photoreceptors</em> in retina detect light</h4>
<p><img src="../include/img/photoreceptors.jpg" class="img-fluid"></p>
<ul>
<li><em>Rods</em>
<ul>
<li>~120 M/eye</li>
<li>Mostly in periphery</li>
<li>Active in low light conditions</li>
<li>One wavelength range</li>
</ul></li>
<li><em>Cones</em>
<ul>
<li>~5 M/eye</li>
<li>Mostly in center</li>
<li>3 wavelength ranges</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://foundationsofvision.stanford.edu/wp-content/uploads/2012/02/rod.cone_.distribution2-1024x467.png" class="img-fluid figure-img"></p>
<figcaption>https://foundationsofvision.stanford.edu/</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/1416_Color_Sensitivity.jpg" class="img-fluid figure-img"></p>
<figcaption>http://cnx.org/content/col11496/1.6/</figcaption>
</figure>
</div>
</section>
<section id="photoreceptor-physiology" class="level4">
<h4 class="anchored" data-anchor-id="photoreceptor-physiology">Photoreceptor physiology</h4>
<ul>
<li>Outer segment
<ul>
<li>Membrane disks</li>
<li><em>Photopigments</em>
<ul>
<li>Sense light, trigger chemical cascade</li>
</ul></li>
</ul></li>
<li>Inner segment
<ul>
<li>Synaptic terminal</li>
</ul></li>
<li>Light <em>hyperpolarizes</em> photoreceptor!
<ul>
<li>The <em>dark current</em></li>
</ul></li>
</ul>
</section>
</section>
<section id="retina" class="level3">
<h3 class="anchored" data-anchor-id="retina">Retina</h3>
<ul>
<li>Physiologically <em>backwards</em>
<ul>
<li><span class="red">Dark current</span></li>
</ul></li>
<li>Anatomically <em>inside-out</em>
<ul>
<li><span class="red">Photoreceptors at back of eye</span></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/retinal-layers.jpg" class="img-fluid figure-img"></p>
<figcaption>http://www.retinareference.com/anatomy/</figcaption>
</figure>
</div>
<ul>
<li>Information flows…
<ul>
<li>From photoreceptors…</li>
<li>To <em>Bipolar cells</em>
<ul>
<li>&lt;-&gt; and <em>Horizontal cells</em></li>
</ul></li>
<li>To <em>Retinal ganglion cells</em>
<ul>
<li>&lt;-&gt; and <em>Amacrine cells</em></li>
</ul></li>
<li>To cerebral cortex</li>
</ul></li>
</ul>
<section id="center-surround-receptive-fields" class="level4">
<h4 class="anchored" data-anchor-id="center-surround-receptive-fields">Center-surround receptive fields</h4>
<p><img src="../include/img/on-center-off-center-receptive-fields.jpg" class="img-fluid"></p>
<ul>
<li>Center region
<ul>
<li>Excites (or inhibits)</li>
</ul></li>
<li>Surround region
<ul>
<li>Does the opposite</li>
</ul></li>
<li>Bipolar cells &amp; Retinal Ganglion cells -&gt;</li>
<li>Most activated by “donuts” of light/dark
<ul>
<li>Local contrast (light/dark differences)</li>
</ul></li>
</ul>
</section>
<section id="opponent-processing" class="level4">
<h4 class="anchored" data-anchor-id="opponent-processing">Opponent processing</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/RGBOpponent.gif" class="img-fluid figure-img"></p>
<figcaption>http://www.visualexpert.com/sbfaqimages/RGBOpponent.gif</figcaption>
</figure>
</div>
<ul>
<li>Black (darker) vs.&nbsp;white (lighter) (achromatic)</li>
<li>Long (red) vs.&nbsp;Medium (green) wavelength cones</li>
<li>(Long + Medium) vs.&nbsp;Short cones</li>
<li>Can’t really see reddish-green or bluish-yellow
<ul>
<li>“Oppose” one another at cellular/circuit level</li>
<li><a href="reddish-green.html">DEMO</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="from-eye-to-brain" class="level3">
<h3 class="anchored" data-anchor-id="from-eye-to-brain">From eye to brain</h3>
<p><img src="../include/img/eye-to-brain.jpg" class="img-fluid"></p>
<ul>
<li>Retinal ganglion cells</li>
<li>2nd/II cranial (optic) nerve
<ul>
<li>Optic chiasm (<span class="math inline">\(\chi\)</span> - asm): Partial crossing of fibers</li>
<li>Nasal hemiretina (lateral/peripheral visual field) cross</li>
<li>Left visual field (from L &amp; R retinae) -&gt; right hemisphere &amp; vice versa</li>
</ul></li>
<li><em>Lateral Geniculate Nucleus (LGN)</em> of thalamus (receives 90% of retinal projections)</li>
<li>Hypothalamus
<ul>
<li><em>Suprachiasmatic nucleus</em> (superior to the optic chiasm): Synchronizes day/night cycle with circadian rhythms</li>
</ul></li>
<li>Superior colliculus &amp; brainstem</li>
</ul>
<section id="lgn" class="level4">
<h4 class="anchored" data-anchor-id="lgn">LGN</h4>
<p><img src="../include/img/lgn.jpg" class="img-fluid"></p>
<ul>
<li>6 layers + intralaminar zone
<ul>
<li>Parvocellular (small cells): chromatic</li>
<li>Magnocellular (big cells): achromatic</li>
<li>Koniocellular (chromatic - <span color="blue">short</span> wavelength?)</li>
</ul></li>
<li>Retinotopic map of opposite visual field</li>
</ul>
</section>
<section id="from-lgn-to-v1" class="level4">
<h4 class="anchored" data-anchor-id="from-lgn-to-v1">From LGN to V1</h4>
<p><img src="../include/img/eye-to-brain.jpg" class="img-fluid"></p>
<ul>
<li>Via <em>optic radiations</em></li>
<li><em><a href="http://www.scholarpedia.org/article/Area_V1">Primary visual cortex (V1)</a></em> in occipital lobe</li>
<li>Create “stria of Gennari” (visible stripe in layer 4)</li>
<li>Calcarine fissure (medial occiptal lobe) divides lower/upper visual field</li>
</ul>
</section>
<section id="human-v1" class="level4">
<h4 class="anchored" data-anchor-id="human-v1">Human V1</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="http://www.scholarpedia.org/w/images/3/3a/03-Human-V1.png" class="img-fluid figure-img"></p>
<figcaption>http://www.scholarpedia.org/w/images/3/3a/03-Human-V1.png</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/mri-v1-retinotopy.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="dougherty_visual_2003">(<a href="#ref-dougherty_visual_2003" role="doc-biblioref">Dougherty et al., 2003</a>)</span></figcaption>
</figure>
</div>
<ul>
<li>Fovea overrepresented
<ul>
<li>Analogous to somatosensation</li>
<li>High acuity in fovea vs.&nbsp;lower outside it</li>
</ul></li>
<li>Upper visual field/lower (ventral) V1 and <em>vice versa</em></li>
</ul>
</section>
<section id="laminar-columnar-organization" class="level4">
<h4 class="anchored" data-anchor-id="laminar-columnar-organization">Laminar, columnar organization</h4>
<p><img src="../include/img/cortical-hypercolumn.jpg" class="img-fluid"></p>
<ul>
<li>6 laminae (layers)
<ul>
<li>Input: Layer 4 (remember stria of Gennari?)</li>
<li>Output: Layers 2-3 (to cortex), 5 (to brainstem), 6 (to LGN)</li>
</ul></li>
<li>Columns
<ul>
<li>Orientation/angle</li>
<li>Spatial frequency</li>
<li>Color/wavelength</li>
<li>Eye of origin, <em>ocular dominance</em></li>
</ul></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/IOHayh06LJ4" frameborder="0" allowfullscreen="">
</iframe>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/dir.selective.png" class="img-fluid figure-img"></p>
<figcaption>https://foundationsofvision.stanford.edu/wp-content/uploads/2012/02/dir.selective.png</figcaption>
</figure>
</div>
</section>
<section id="from-center-surround-receptive-fields-to-line-detection" class="level4">
<h4 class="anchored" data-anchor-id="from-center-surround-receptive-fields-to-line-detection">From center-surround receptive fields to line detection</h4>
<p><img src="http://www.scholarpedia.org/w/images/9/99/11-Hubel-Wiesel-model.png" class="img-fluid"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../include/img/spatial-freq-fpsyg-03-00620-g003.jpg" class="img-fluid figure-img"></p>
<figcaption><span class="citation" data-cites="panichello_predictive_2013">(<a href="#ref-panichello_predictive_2013" role="doc-biblioref">Panichello, Cheung, &amp; Bar, 2013</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="ocular-dominance-columns" class="level4">
<h4 class="anchored" data-anchor-id="ocular-dominance-columns">Ocular dominance columns</h4>
<p><img src="../include/img/cortical-hypercolumn.jpg" class="img-fluid"></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KjAQdc29vF8" frameborder="0" allowfullscreen="">
</iframe>
</section>
</section>
<section id="beyond-v1" class="level3">
<h3 class="anchored" data-anchor-id="beyond-v1">Beyond V1</h3>
<p><img src="../include/img/beyond-v1.jpg" class="img-fluid"></p>
<ul>
<li>Larger, more complex receptive fields</li>
<li><em>Dorsal stream</em> (where/how)
<ul>
<li>Toward parietal lobe</li>
</ul></li>
<li><em>Ventral stream</em> (what)</li>
</ul>
</section>
<section id="what-is-vision-for" class="level3">
<h3 class="anchored" data-anchor-id="what-is-vision-for">What is vision for?</h3>
<ul>
<li>What is it? (form perception)</li>
<li>Where is it? (space perception)</li>
<li>How do I get from here to there (action control)</li>
<li>What time (or time of year) is it?</li>
</ul>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-dougherty_visual_2003" class="csl-entry" role="listitem">
Dougherty, R. F., Koch, V. M., Brewer, A. A., Fischer, B., Modersitzki, J., &amp; Wandell, B. A. (2003). Visual field representations and locations of visual areas <span>V</span>1/2/3 in human visual cortex. <em>Journal of Vision</em>, <em>3</em>(10), 1–1. <a href="https://doi.org/10.1167/3.10.1">https://doi.org/10.1167/3.10.1</a>
</div>
<div id="ref-Namkung2017-gc" class="csl-entry" role="listitem">
Namkung, H., Kim, S.-H., &amp; Sawa, A. (2017). The insula: An underestimated brain area in clinical neuroscience, psychiatry, and neurology. <em>Trends in Neurosciences</em>, <em>40</em>(4), 200–207. <a href="https://doi.org/10.1016/j.tins.2017.02.002">https://doi.org/10.1016/j.tins.2017.02.002</a>
</div>
<div id="ref-panichello_predictive_2013" class="csl-entry" role="listitem">
Panichello, M. F., Cheung, O. S., &amp; Bar, M. (2013). Predictive feedback and conscious visual experience. <em>Perception Science</em>, <em>3</em>, 620. <a href="https://doi.org/10.3389/fpsyg.2012.00620">https://doi.org/10.3389/fpsyg.2012.00620</a>
</div>
<div id="ref-Randeberg2005-xn" class="csl-entry" role="listitem">
Randeberg, L. (2005). Diagnostic applications of diffuse reflectance spectroscopy. Retrieved from <a href="https://www.semanticscholar.org/paper/ec9450b79923e2e2152b54ab9241b60bc5374944">https://www.semanticscholar.org/paper/ec9450b79923e2e2152b54ab9241b60bc5374944</a>
</div>
<div id="ref-Roark2019-fx" class="csl-entry" role="listitem">
Roark, M. W., &amp; Stringham, J. M. (2019). Visual performance in the <span>“real world”</span>: Contrast sensitivity, visual acuity, and effects of macular carotenoids. <em>Molecular Nutrition &amp; Food Research</em>, <em>63</em>(15), e1801053. <a href="https://doi.org/10.1002/mnfr.201801053">https://doi.org/10.1002/mnfr.201801053</a>
</div>
<div id="ref-Smith2021-ho" class="csl-entry" role="listitem">
Smith, G. E., Chouinard, P. A., &amp; Byosiere, S.-E. (2021). If <span>I</span> fits <span>I</span> sits: A citizen science investigation into illusory contour susceptibility in domestic cats (felis silvestris catus). <em>Applied Animal Behaviour Science</em>, <em>240</em>, 105338. <a href="https://doi.org/10.1016/j.applanim.2021.105338">https://doi.org/10.1016/j.applanim.2021.105338</a>
</div>
<div id="ref-swanson2005anatomy" class="csl-entry" role="listitem">
Swanson, L. W. (2005). Anatomy of the soul as reflected in the cerebral hemispheres: Neural circuits underlying voluntary control of basic motivated behaviors. <em>Journal of Comparative Neurology</em>, <em>493</em>(1), 122–131. <a href="https://doi.org/10.1002/cne.20733">https://doi.org/10.1002/cne.20733</a>
</div>
<div id="ref-swanson2012brain" class="csl-entry" role="listitem">
Swanson, L. W. (2012). <em>Brain architecture: <span>U</span>nderstanding the basic plan</em>. Oxford University Press.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright © 2025- Rick Gilmore</p>
</div>   
    <div class="nav-footer-center">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/psu-psychology/psy-511-scan-fdns-2025-spring/edit/main/src/resources/perception.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/psu-psychology/psy-511-scan-fdns-2025-spring/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/psu-psychology/psy-511-scan-fdns-2025-spring">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>